# -*- coding: utf-8 -*-
"""Code_ML pipline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10waYKklJDbQeTl0_W8wq2EcCUMB5J619
"""

!pip -q install osfclient open-clip-torch==2.24.0 ftfy tqdm scikit-learn joblib pillow
import os, json, numpy as np, torch, open_clip, zipfile, glob
from pathlib import Path
from PIL import Image
from tqdm import tqdm

device = "cuda" if torch.cuda.is_available() else "cpu"
torch.set_num_threads(2)
print("Device:", device)

# OSF components
EEG_COMP   = "anp5v"  # Preprocessed EEG (zips per subject)
BEHAV_COMP = "b56ha"  # Behavioral zip (not used for filenames here)
IMGS_COMP  = "y63gw"  # Image sets + metadata

Path("data/sub-01/eeg").mkdir(parents=True, exist_ok=True)
Path("data/images").mkdir(parents=True, exist_ok=True)

# Fetch EEG train/test container zip and extract only the needed .npy files
!osf -p {EEG_COMP} fetch "osfstorage/sub-01.zip" "sub01_eeg.zip"
with zipfile.ZipFile("sub01_eeg.zip") as z:
    z.extract("sub-01/preprocessed_eeg_training.npy", "data/sub-01/eeg")
    z.extract("sub-01/preprocessed_eeg_test.npy", "data/sub-01/eeg")
!rm -f sub01_eeg.zip

# Fetch image metadata + train/test image zips
!osf -p {IMGS_COMP} fetch "osfstorage/image_metadata.npy" "data/images/image_metadata.npy"
!osf -p {IMGS_COMP} fetch "osfstorage/training_images.zip" "training_images.zip"
!osf -p {IMGS_COMP} fetch "osfstorage/test_images.zip" "test_images.zip"

# Unzip images
with zipfile.ZipFile("training_images.zip") as z:
    z.extractall("data/images/train")
with zipfile.ZipFile("test_images.zip") as z:
    z.extractall("data/images/test")
!rm -f training_images.zip test_images.zip

print("Downloads done.")

import numpy as np

tr = np.load("data/sub-01/eeg/sub-01/preprocessed_eeg_training.npy", allow_pickle=True).item()
te = np.load("data/sub-01/eeg/sub-01/preprocessed_eeg_test.npy", allow_pickle=True).item()

# Train: shape (16540, repeats=4, ch=17, t=100)
Xtr = tr["preprocessed_eeg_data"].mean(axis=1).astype("float32")  # (16540,17,100)
Xtr = Xtr.reshape(len(Xtr), -1)                                    # (16540,1700)
np.save("train_features_erp_raw.npy", Xtr)

# Test: shape (200, ch=80, repeats=17, t=100) → pick same 17 channels as train
name_to_idx = {n:i for i,n in enumerate(te["ch_names"])}
idx = [name_to_idx[c] for c in tr["ch_names"]]
Xte = te["preprocessed_eeg_data"].mean(axis=2)[:, idx, :].astype("float32")  # (200,17,100)
Xte = Xte.reshape(len(Xte), -1)                                              # (200,1700)
np.save("test_features_erp17_raw.npy", Xte)

print("Train ERP:", Xtr.shape, "Test ERP:", Xte.shape)

def index_images(root):
    idx = {}
    for p in glob.glob(os.path.join(root, "**", "*.jpg"), recursive=True):
        idx[os.path.basename(p)] = p
    return idx

m = np.load("data/images/image_metadata.npy", allow_pickle=True).item()
train_files = list(m["train_img_files"])
test_files  = list(m["test_img_files"])

train_idx = index_images("data/images/train/training_images")
test_idx  = index_images("data/images/test/test_images")

model, _, preprocess = open_clip.create_model_and_transforms("ViT-B-32", pretrained="openai", device=device)
model.eval()

def embed_files(files, idx_map, batch=128):
    vecs = []
    cur = []
    for i, fname in enumerate(tqdm(files, desc="embedding")):
        p = idx_map.get(os.path.basename(fname))
        if p is None:
            cur.append(None)
        else:
            im = Image.open(p).convert("RGB")
            cur.append(preprocess(im).unsqueeze(0))
        if len(cur) == batch or i == len(files)-1:
            imgs = [x for x in cur if x is not None]
            if imgs:
                X = torch.cat(imgs, dim=0).to(device)
                with torch.no_grad():
                    F = model.encode_image(X)
                    F = F / F.norm(dim=-1, keepdim=True)
                F = F.detach().cpu().numpy().astype("float32")
                # stitch back with zeros for missing
                j = 0
                out = []
                for x in cur:
                    if x is None:
                        out.append(np.zeros((1,512), dtype="float32"))
                    else:
                        out.append(F[j:j+1]); j += 1
                vecs.append(np.concatenate(out, axis=0))
            else:
                vecs.append(np.zeros((len(cur),512), dtype="float32"))
            cur = []
    return np.concatenate(vecs, axis=0)

Ft = embed_files(train_files, train_idx)   # (16540,512)
Fg = embed_files(test_files,  test_idx)    # (200,512)
np.save("train_imgclip.npy", Ft)
np.save("test_imgclip.npy",  Fg)
print("Train imgs:", Ft.shape, "Test imgs:", Fg.shape)

from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
import joblib

# PCA→64 on train images, then transform test
pca = PCA(n_components=64, random_state=0)
Ft64 = pca.fit_transform(np.load("train_imgclip.npy"))
Fg64 = pca.transform(np.load("test_imgclip.npy"))
np.save("train_imgclip_pca64.npy", Ft64.astype("float32"))
np.save("test_imgclip_pca64.npy",  Fg64.astype("float32"))
joblib.dump(pca, "pca64.joblib")

# Train small MLP EEG->PCA64
Xtr = np.load("train_features_erp_raw.npy").astype("float32")
Xte = np.load("test_features_erp17_raw.npy").astype("float32")

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("mlp", MLPRegressor(hidden_layer_sizes=(512,256),
                         activation="relu",
                         alpha=1e-4,
                         learning_rate="adaptive",
                         learning_rate_init=1e-3,
                         batch_size=128,
                         max_iter=200,
                         early_stopping=True,
                         n_iter_no_change=10,
                         random_state=0,
                         verbose=True))
])
pipe.fit(Xtr, Ft64)

# Evaluate on 200-image gallery (PCA64)
def l2(a):
    n = np.linalg.norm(a, axis=1, keepdims=True)+1e-8
    return a/n

Yp = l2(pipe.predict(Xte).astype("float32"))
G  = l2(Fg64.astype("float32"))
S  = Yp @ G.T
I1 = np.argmax(S, axis=1)
acc1 = (I1 == np.arange(G.shape[0])).mean()
I5 = np.argpartition(-S, 5, axis=1)[:, :5]
acc5 = np.mean([i in row for i, row in enumerate(I5)])

print(f"MLP — TEST PCA64: top1={acc1:.3f}, top5={acc5:.3f}")

# Save mapper + PCA for your app
Path("models").mkdir(exist_ok=True)
joblib.dump(pipe, "models/mapper.joblib")
joblib.dump(pca,  "models/pca64.joblib")
print("Saved models/mapper.joblib and models/pca64.joblib")

from google.colab import files
files.download("models/mapper.joblib")
files.download("models/pca64.joblib")